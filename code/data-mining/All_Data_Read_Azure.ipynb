{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Queries Running on entire Dataset in Azure \n",
        "\n",
        "Using the Azure Blob location with the project data: wasbs://reddit-project@dsan6000fall2024.blob.core.windows.net/<DIRECTORY>/."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 20,
              "statement_ids": [
                20
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:37:58.7646436Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:37:58.9451455Z",
              "execution_finish_time": "2024-11-25T03:37:59.2641759Z",
              "parent_msg_id": "64d7d6cc-1287-40bd-ba2a-5aed6fccd033"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 20, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "<pyspark.sql.session.SparkSession at 0x783ab95105e0>",
            "text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://vm-3e109119:36961\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.4.3.5.3.20241016.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Azure ML Experiment</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1732505879386
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up Data Configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob_account_name = \"dsan6000fall2024\"\n",
        "blob_container_name = \"reddit-project\"\n",
        "wasbs_base_url = (\n",
        "    f\"wasbs://{blob_container_name}@{blob_account_name}.blob.core.windows.net/\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 21,
              "statement_ids": [
                21
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:38:01.4135827Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:38:01.5353194Z",
              "execution_finish_time": "2024-11-25T03:38:01.8384464Z",
              "parent_msg_id": "e24f15d7-e64e-4faa-a1fa-e809ab9026ca"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 21, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732505881924
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reading in a single parquet file "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_path = \"202306-202407/comments/\"\n",
        "submissions_path = \"202306-202407/submissions/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 22,
              "statement_ids": [
                22
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:38:05.3457903Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:38:05.4637046Z",
              "execution_finish_time": "2024-11-25T03:38:05.7810465Z",
              "parent_msg_id": "0827b659-03ed-486d-b868-5a41a8e4bfac"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 22, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732505885845
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test on a single file only (random file)\n",
        "\n",
        "# comments_single = \"yyyy=2023/mm=11/comments_RC_2023-11.zst_9.parquet\"\n",
        "# submissions_single = \"yyyy=2023/mm=11/submissions_RS_2023-11.zst_36.parquet\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 10,
              "statement_ids": [
                10
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:04.1045073Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:04.5351283Z",
              "execution_finish_time": "2024-11-24T21:44:05.6603384Z",
              "parent_msg_id": "6c207f9f-1ee9-4fc8-bb78-7c42dc1b88f5"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 10, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484645737
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\n",
        "# submissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 11,
              "statement_ids": [
                11
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 1,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\ncomments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\nsubmissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")",
                    "submissionTime": "2024-11-24T21:44:15.165GMT",
                    "completionTime": "2024-11-24T21:44:15.367GMT",
                    "stageIds": [
                      1
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 0,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 11:\ncomments_single_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_single}\")\nsubmissions_single_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_single}\")",
                    "submissionTime": "2024-11-24T21:44:07.684GMT",
                    "completionTime": "2024-11-24T21:44:13.833GMT",
                    "stageIds": [
                      0
                    ],
                    "jobGroup": "11",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:06.6202349Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:06.7456341Z",
              "execution_finish_time": "2024-11-24T21:44:16.8325875Z",
              "parent_msg_id": "0b2d1f97-36cf-444c-90d1-40ea2ad89e2d"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 11, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484656911
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Initial exploration\n",
        "Schema & Row count\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_single_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 12,
              "statement_ids": [
                12
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:18.2265333Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:18.3567245Z",
              "execution_finish_time": "2024-11-24T21:44:18.6996816Z",
              "parent_msg_id": "69992a1e-99c8-4152-9e12-90d07ca86d39"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 12, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- body: string (nullable = true)\n |-- controversiality: long (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- gilded: long (nullable = true)\n |-- id: string (nullable = true)\n |-- link_id: string (nullable = true)\n |-- parent_id: string (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484658786
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_row_count = comments_single_df.count()\n",
        "# comment_col_count = len(comments_single_df.columns)\n",
        "# print(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 13,
              "statement_ids": [
                13
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 451,
                    "rowCount": 8,
                    "usageDescription": "",
                    "jobId": 3,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 13:\ncomments_row_count = comments_single_df.count()\ncomment_col_count = len(comments_single_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:29.567GMT",
                    "completionTime": "2024-11-24T21:44:30.161GMT",
                    "stageIds": [
                      3,
                      4
                    ],
                    "jobGroup": "13",
                    "status": "SUCCEEDED",
                    "numTasks": 9,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 8,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 451,
                    "dataRead": 91070,
                    "rowCount": 1000008,
                    "usageDescription": "",
                    "jobId": 2,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 13:\ncomments_row_count = comments_single_df.count()\ncomment_col_count = len(comments_single_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:23.010GMT",
                    "completionTime": "2024-11-24T21:44:29.462GMT",
                    "stageIds": [
                      2
                    ],
                    "jobGroup": "13",
                    "status": "SUCCEEDED",
                    "numTasks": 8,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 8,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 8,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:21.0741579Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:21.1944334Z",
              "execution_finish_time": "2024-11-24T21:44:31.2499196Z",
              "parent_msg_id": "135569ff-8277-4355-be2c-d0a6ec694b49"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 13, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the comments dataframe is 1,000,000x17\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484671352
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_single_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 14,
              "statement_ids": [
                14
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:34.4175925Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:34.5366607Z",
              "execution_finish_time": "2024-11-24T21:44:34.8512373Z",
              "parent_msg_id": "84037465-4deb-44ac-88f0-f7a02d9e1add"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 14, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- domain: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- id: string (nullable = true)\n |-- is_self: boolean (nullable = true)\n |-- locked: boolean (nullable = true)\n |-- num_comments: long (nullable = true)\n |-- over_18: boolean (nullable = true)\n |-- quarantine: boolean (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- selftext: string (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n |-- title: string (nullable = true)\n |-- url: string (nullable = true)\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484674941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_row_count = submissions_single_df.count()\n",
        "# submissions_col_count = len(submissions_single_df.columns)\n",
        "# print(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 15,
              "statement_ids": [
                15
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 451,
                    "rowCount": 8,
                    "usageDescription": "",
                    "jobId": 5,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 15:\nsubmissions_row_count = submissions_single_df.count()\nsubmissions_col_count = len(submissions_single_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:37.800GMT",
                    "completionTime": "2024-11-24T21:44:38.061GMT",
                    "stageIds": [
                      6,
                      7
                    ],
                    "jobGroup": "15",
                    "status": "SUCCEEDED",
                    "numTasks": 9,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 8,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 451,
                    "dataRead": 112250,
                    "rowCount": 1000008,
                    "usageDescription": "",
                    "jobId": 4,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 15:\nsubmissions_row_count = submissions_single_df.count()\nsubmissions_col_count = len(submissions_single_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:37.467GMT",
                    "completionTime": "2024-11-24T21:44:37.768GMT",
                    "stageIds": [
                      5
                    ],
                    "jobGroup": "15",
                    "status": "SUCCEEDED",
                    "numTasks": 8,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 8,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 8,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:37.168481Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:37.3243729Z",
              "execution_finish_time": "2024-11-24T21:44:38.8670122Z",
              "parent_msg_id": "88081ebf-6e0a-4393-bd64-ed406ef8d6d0"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 15, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the submissions dataframe is 1,000,000x21\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484679015
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading in an entire month"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test on a single month\n",
        "# comments_month = \"yyyy=2023/mm=11/\"\n",
        "# submissions_month = \"yyyy=2023/mm=11/\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 16,
              "statement_ids": [
                16
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:42.2550711Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:42.3757868Z",
              "execution_finish_time": "2024-11-24T21:44:42.7001358Z",
              "parent_msg_id": "b01e2a0d-7e2f-4751-a46d-04d3c1b6b748"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 16, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484682764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\n",
        "# submissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 17,
              "statement_ids": [
                17
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 7,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 17:\ncomments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\nsubmissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")",
                    "submissionTime": "2024-11-24T21:44:46.618GMT",
                    "completionTime": "2024-11-24T21:44:46.787GMT",
                    "stageIds": [
                      9
                    ],
                    "jobGroup": "17",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 6,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 17:\ncomments_months_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}{comments_month}\")\nsubmissions_months_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}{submissions_month}\")",
                    "submissionTime": "2024-11-24T21:44:45.861GMT",
                    "completionTime": "2024-11-24T21:44:46.322GMT",
                    "stageIds": [
                      8
                    ],
                    "jobGroup": "17",
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:45.1490499Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:45.267701Z",
              "execution_finish_time": "2024-11-24T21:44:47.7163339Z",
              "parent_msg_id": "30a92103-b90b-4517-8483-677fe1ad938c"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 17, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484687787
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Initial exploration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_row_count = comments_months_df.count()\n",
        "# comment_col_count = len(comments_months_df.columns)\n",
        "# print(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 18,
              "statement_ids": [
                18
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 14396,
                    "rowCount": 244,
                    "usageDescription": "",
                    "jobId": 9,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\ncomments_row_count = comments_months_df.count()\ncomment_col_count = len(comments_months_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:54.571GMT",
                    "completionTime": "2024-11-24T21:44:54.692GMT",
                    "stageIds": [
                      12,
                      11
                    ],
                    "jobGroup": "18",
                    "status": "SUCCEEDED",
                    "numTasks": 245,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 244,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 14396,
                    "dataRead": 4479843,
                    "rowCount": 243870598,
                    "usageDescription": "",
                    "jobId": 8,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\ncomments_row_count = comments_months_df.count()\ncomment_col_count = len(comments_months_df.columns)\nprint(f\"shape of the comments dataframe is {comments_row_count:,}x{comment_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:51.105GMT",
                    "completionTime": "2024-11-24T21:44:54.518GMT",
                    "stageIds": [
                      10
                    ],
                    "jobGroup": "18",
                    "status": "SUCCEEDED",
                    "numTasks": 244,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 244,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 244,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:50.8666948Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:50.9928145Z",
              "execution_finish_time": "2024-11-24T21:44:56.0919439Z",
              "parent_msg_id": "6a0d6831-6d48-4a06-9f14-bbe331edc226"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 18, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the comments dataframe is 243,870,354x17\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484696218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# submissions_row_count = submissions_months_df.count()\n",
        "# submissions_col_count = len(submissions_months_df.columns)\n",
        "# print(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 19,
              "statement_ids": [
                19
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 2525,
                    "rowCount": 43,
                    "usageDescription": "",
                    "jobId": 11,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\nsubmissions_row_count = submissions_months_df.count()\nsubmissions_col_count = len(submissions_months_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:57.406GMT",
                    "completionTime": "2024-11-24T21:44:57.461GMT",
                    "stageIds": [
                      15,
                      14
                    ],
                    "jobGroup": "19",
                    "status": "SUCCEEDED",
                    "numTasks": 44,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 43,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 2525,
                    "dataRead": 1421880,
                    "rowCount": 38107510,
                    "usageDescription": "",
                    "jobId": 10,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\nsubmissions_row_count = submissions_months_df.count()\nsubmissions_col_count = len(submissions_months_df.columns)\nprint(f\"shape of the submissions dataframe is {submissions_row_count:,}x{submissions_col_count}\")",
                    "submissionTime": "2024-11-24T21:44:56.306GMT",
                    "completionTime": "2024-11-24T21:44:57.380GMT",
                    "stageIds": [
                      13
                    ],
                    "jobGroup": "19",
                    "status": "SUCCEEDED",
                    "numTasks": 43,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 43,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 43,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:44:54.9276012Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:44:56.2252876Z",
              "execution_finish_time": "2024-11-24T21:44:57.8216058Z",
              "parent_msg_id": "ab670d0c-03a6-4ece-b4e8-0b24db0db237"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 19, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "shape of the submissions dataframe is 38,107,467x21\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484697912
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading in all of the Reddit data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\n",
        "submissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 2,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 22,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 23:\ncomments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\nsubmissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")",
                    "submissionTime": "2024-11-25T03:38:54.736GMT",
                    "completionTime": "2024-11-25T03:38:54.809GMT",
                    "stageIds": [
                      29
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 21,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 23:\ncomments_df = spark.read.parquet(f\"{wasbs_base_url}{comments_path}\")\nsubmissions_df = spark.read.parquet(f\"{wasbs_base_url}{submissions_path}\")",
                    "submissionTime": "2024-11-25T03:38:53.911GMT",
                    "completionTime": "2024-11-25T03:38:54.035GMT",
                    "stageIds": [
                      28
                    ],
                    "jobGroup": "23",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:38:51.600093Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:38:51.7559198Z",
              "execution_finish_time": "2024-11-25T03:38:55.2981427Z",
              "parent_msg_id": "ef28cb7e-34e7-4030-9db4-8ef8c4a42079"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 23, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732505935801
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissions_df.count()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 24,
              "statement_ids": [
                24
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 2,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 37447,
                    "rowCount": 638,
                    "usageDescription": "",
                    "jobId": 24,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 24:\nsubmissions_df.count()",
                    "submissionTime": "2024-11-25T03:39:09.071GMT",
                    "completionTime": "2024-11-25T03:39:09.206GMT",
                    "stageIds": [
                      31,
                      32
                    ],
                    "jobGroup": "24",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 639,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 638,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 37447,
                    "dataRead": 19914817,
                    "rowCount": 567891507,
                    "usageDescription": "",
                    "jobId": 23,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 24:\nsubmissions_df.count()",
                    "submissionTime": "2024-11-25T03:39:01.550GMT",
                    "completionTime": "2024-11-25T03:39:09.048GMT",
                    "stageIds": [
                      30
                    ],
                    "jobGroup": "24",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 638,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 638,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 638,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:39:01.3162278Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:39:01.4438025Z",
              "execution_finish_time": "2024-11-25T03:39:10.8184081Z",
              "parent_msg_id": "3ef0bf66-649c-4709-a859-bd0a96ccc489"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 24, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "567890869"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732505950905
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submissions_df.rdd.getNumPartitions()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 21,
              "statement_ids": [
                21
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:28:26.9198695Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:28:27.0539414Z",
              "execution_finish_time": "2024-11-24T21:28:27.9060498Z",
              "parent_msg_id": "24e12264-8683-4aab-ac25-bb9cd43a4333"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 21, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "638"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483708068
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.count()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 22,
              "statement_ids": [
                22
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 2,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 216943,
                    "rowCount": 3677,
                    "usageDescription": "",
                    "jobId": 17,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 22:\ncomments_df.count()",
                    "submissionTime": "2024-11-24T21:29:16.491GMT",
                    "completionTime": "2024-11-24T21:29:17.242GMT",
                    "stageIds": [
                      22,
                      23
                    ],
                    "jobGroup": "22",
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 216943,
                    "dataRead": 66832605,
                    "rowCount": 3675772635,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 22:\ncomments_df.count()",
                    "submissionTime": "2024-11-24T21:28:34.921GMT",
                    "completionTime": "2024-11-24T21:29:16.438GMT",
                    "stageIds": [
                      21
                    ],
                    "jobGroup": "22",
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:28:34.6091083Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:28:34.7285382Z",
              "execution_finish_time": "2024-11-24T21:29:19.3401421Z",
              "parent_msg_id": "c3aba2b0-cb64-48b3-ae42-49e444cedc94"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 22, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "3675768958"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483759466
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.rdd.getNumPartitions()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "3",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:30:17.5604817Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:30:17.7008462Z",
              "execution_finish_time": "2024-11-24T21:30:19.8177856Z",
              "parent_msg_id": "299320c7-0e54-4772-b88c-29b31db2696a"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 3, 23, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "3677"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732483819984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comments_df.printSchema()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 22,
              "statement_ids": [
                22
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "finished",
              "queued_time": "2024-11-24T21:45:14.2208138Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:45:16.7908971Z",
              "execution_finish_time": "2024-11-24T21:45:17.1063296Z",
              "parent_msg_id": "7c20be23-89d4-4385-95a5-66e27121abf5"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 22, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "root\n |-- author: string (nullable = true)\n |-- author_flair_css_class: string (nullable = true)\n |-- author_flair_text: string (nullable = true)\n |-- body: string (nullable = true)\n |-- controversiality: long (nullable = true)\n |-- created_utc: long (nullable = true)\n |-- distinguished: string (nullable = true)\n |-- edited: double (nullable = true)\n |-- gilded: long (nullable = true)\n |-- id: string (nullable = true)\n |-- link_id: string (nullable = true)\n |-- parent_id: string (nullable = true)\n |-- retrieved_on: long (nullable = true)\n |-- score: long (nullable = true)\n |-- stickied: boolean (nullable = true)\n |-- subreddit: string (nullable = true)\n |-- subreddit_id: string (nullable = true)\n |-- yyyy: integer (nullable = true)\n |-- mm: integer (nullable = true)\n\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484717189
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Queries Part 1 \n",
        "\n",
        "#### Sorting Subreddits Relevant to: \n",
        "\n",
        "(A1, B3a, B13), A2b, A3a, A3b\n",
        "\n",
        "* Frustrating or frustrat and cancer (HINTS A2b)\n",
        "* cancer and doctors or trust (i.e. does not need to contain trust because trust is included in the NRC sentiment analysis) (HINTS A3a)\n",
        "* cancer and family or friends or sister or brother or mother or mom or father or mother or cousin or aunt or uncle or trust (HINTS A3b)\n",
        "\n",
        "HINTS Questions: \n",
        "\n",
        "* SeekCancerInfo: A1 | Have you ever looked for information about cancer from any source?\n",
        "* Electronic2_HealthInfo: B3a | In the past 12 months have you used the Internet to look for health or medical information?\n",
        "* MisleadingHealthInfo: B13 | How much of the health information that you see on social media do you think is false or misleading?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "\n",
        "# sample approximately 0.001% of the data and limit to 50 rows\n",
        "comments_subset_df = comments_df.sample(withReplacement=False, fraction=0.001, seed=42).limit(50)\n",
        "\n",
        "# Display the first few rows of subset DataFrame\n",
        "comments_subset_df.show(5)\n",
        "\n",
        "# Display the size (number of rows) in the df\n",
        "print(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 25,
              "statement_ids": [
                25
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 3,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 27,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 25:\nfrom pyspark.sql.functions import col, lower\n\n# sample approximately 0.001% of the data and limit to 50 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.001, seed=42).limit(50)\n\n# Display the first few rows of subset DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the df\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-25T03:40:05.849GMT",
                    "completionTime": "2024-11-25T03:40:05.970GMT",
                    "stageIds": [
                      35,
                      36
                    ],
                    "jobGroup": "25",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "count at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 194881,
                    "dataRead": 67255342,
                    "rowCount": 191434282,
                    "usageDescription": "",
                    "jobId": 26,
                    "name": "count at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 25:\nfrom pyspark.sql.functions import col, lower\n\n# sample approximately 0.001% of the data and limit to 50 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.001, seed=42).limit(50)\n\n# Display the first few rows of subset DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the df\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-25T03:39:37.077GMT",
                    "completionTime": "2024-11-25T03:40:05.816GMT",
                    "stageIds": [
                      34
                    ],
                    "jobGroup": "25",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 115842396,
                    "rowCount": 12288,
                    "usageDescription": "",
                    "jobId": 25,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 25:\nfrom pyspark.sql.functions import col, lower\n\n# sample approximately 0.001% of the data and limit to 50 rows\ncomments_subset_df = comments_df.sample(withReplacement=False, fraction=0.001, seed=42).limit(50)\n\n# Display the first few rows of subset DataFrame\ncomments_subset_df.show(5)\n\n# Display the size (number of rows) in the df\nprint(f\"Number of rows in the sampled and limited DataFrame: {comments_subset_df.count()}\")\n",
                    "submissionTime": "2024-11-25T03:39:33.728GMT",
                    "completionTime": "2024-11-25T03:39:36.870GMT",
                    "stageIds": [
                      33
                    ],
                    "jobGroup": "25",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 1,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:39:33.4577929Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:39:33.578699Z",
              "execution_finish_time": "2024-11-25T03:40:06.2906398Z",
              "parent_msg_id": "5478b1ca-5d6e-4359-b2c9-cc75ab1ad917"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 25, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+--------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------+------------+----+---+\n|        author|author_flair_css_class|author_flair_text|                body|controversiality|created_utc|distinguished|edited|gilded|     id|   link_id| parent_id|retrieved_on|score|stickied|     subreddit|subreddit_id|yyyy| mm|\n+--------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------+------------+----+---+\n| LordMasoud7th|                  null|             null|just playing P4G ...|               0| 1701783383|         null|  null|     0|kc3blge|t3_18b9b9d|t3_18b9b9d|  1701783399|   21|   false|persona4golden|    t5_2waqy|2023| 12|\n|       Flip264|                  null|             null|Local staff at an...|               0| 1701783384|         null|  null|     0|kc3bljj|t3_18b9t2p|t3_18b9t2p|  1701783399|   19|   false|     japanlife|    t5_2rg2o|2023| 12|\n|  ferdinando81|                  null|             null|It look tasty, dm...|               0| 1701783387|         null|  null|     0|kc3blpw|t3_18b91aq|t3_18b91aq|  1701783404|    1|   false|    OttawaNSFW|   t5_34av1v|2023| 12|\n|user-friendly_|                  null|             null|I literally said ...|               0| 1701783394|         null|  null|     0|kc3bm8e|t3_18b1wix|t1_kc2z1kh|  1701783408|    1|   false|    Michigents|    t5_2tnu7|2023| 12|\n|   BlueRain369|                  null|             null|The interracial c...|               0| 1701783402|         null|  null|     0|kc3bmrq|t3_18bbigt|t3_18bbigt|  1701783417|    7|   false|MuslimMarriage|    t5_39x1d|2023| 12|\n+--------------+----------------------+-----------------+--------------------+----------------+-----------+-------------+------+------+-------+----------+----------+------------+-----+--------+--------------+------------+----+---+\nonly showing top 5 rows\n\nNumber of rows in the sampled and limited DataFrame: 50\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732506006449
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Spark SQL warehouse directory\n",
        "print(f\"Spark SQL Warehouse Directory: {spark.conf.get('spark.sql.warehouse.dir')}\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 26,
              "statement_ids": [
                26
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T03:39:56.4110313Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T03:40:06.4286709Z",
              "execution_finish_time": "2024-11-25T03:40:06.7388517Z",
              "parent_msg_id": "9ca46ec5-ad51-4220-ac1a-d16b9bad91d6"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 26, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Spark SQL Warehouse Directory: wasbs://0844dfc1-917d-4630-9fe7-89d921fd4a38@hobostoragej94ibmh28y.blob.core.windows.net/synapse/workspaces/becc8696-e562-432e-af12-8a5e3e1f9b0f/warehouse\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732506006851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lower\n",
        "\n",
        "# # Print the Spark SQL warehouse directory\n",
        "# print(f\"Spark SQL Warehouse Directory: {spark.conf.get('spark.sql.warehouse.dir')}\")\n",
        "\n",
        "# Filter the subset for comments containing \"frustrat\" and \"cancer\"\n",
        "filtered_comments_subset_df = comments_subset_df.filter(\n",
        "    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n",
        ")\n",
        "\n",
        "# Preview the filtered DataFrame\n",
        "filtered_comments_subset_df.show(5)\n",
        "\n",
        "# Save the filtered subset to a Parquet file\n",
        "output_test_file = \"Test_Query_A2b.parquet\"\n",
        "filtered_comments_subset_df.write.parquet(output_test_file, mode=\"overwrite\")\n",
        "\n",
        "print(f\"Test results saved to {output_test_file}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 18,
              "statement_ids": [
                18
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 4,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 1916,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\nfrom pyspark.sql.functions import col, lower\n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a Parquet file\noutput_test_file = \"Test_Query_A2b.parquet\"\nfiltered_comments_subset_df.write.parquet(output_test_file, mode=\"overwrite\")\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:34:05.834GMT",
                    "completionTime": "2024-11-25T02:34:07.481GMT",
                    "stageIds": [
                      20,
                      21
                    ],
                    "jobGroup": "18",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "parquet at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 45662716,
                    "dataRead": 396700700646,
                    "rowCount": 191434282,
                    "usageDescription": "",
                    "jobId": 15,
                    "name": "parquet at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\nfrom pyspark.sql.functions import col, lower\n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a Parquet file\noutput_test_file = \"Test_Query_A2b.parquet\"\nfiltered_comments_subset_df.write.parquet(output_test_file, mode=\"overwrite\")\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:12:33.389GMT",
                    "completionTime": "2024-11-25T02:34:05.525GMT",
                    "stageIds": [
                      19
                    ],
                    "jobGroup": "18",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 14,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\nfrom pyspark.sql.functions import col, lower\n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a Parquet file\noutput_test_file = \"Test_Query_A2b.parquet\"\nfiltered_comments_subset_df.write.parquet(output_test_file, mode=\"overwrite\")\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:12:32.957GMT",
                    "completionTime": "2024-11-25T02:12:33.144GMT",
                    "stageIds": [
                      17,
                      18
                    ],
                    "jobGroup": "18",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 45662716,
                    "dataRead": 396700700646,
                    "rowCount": 191434282,
                    "usageDescription": "",
                    "jobId": 13,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 18:\nfrom pyspark.sql.functions import col, lower\n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a Parquet file\noutput_test_file = \"Test_Query_A2b.parquet\"\nfiltered_comments_subset_df.write.parquet(output_test_file, mode=\"overwrite\")\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T01:51:09.461GMT",
                    "completionTime": "2024-11-25T02:12:32.853GMT",
                    "stageIds": [
                      16
                    ],
                    "jobGroup": "18",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T01:51:09.1092947Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T01:51:09.2194852Z",
              "execution_finish_time": "2024-11-25T02:34:10.82428Z",
              "parent_msg_id": "79c900c8-e124-44da-a444-351cb7cf7130"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 18, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n|author|author_flair_css_class|author_flair_text|body|controversiality|created_utc|distinguished|edited|gilded| id|link_id|parent_id|retrieved_on|score|stickied|subreddit|subreddit_id|yyyy| mm|\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n\nTest results saved to Test_Query_A2b.parquet\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732502051178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous Code to save as .csv \n",
        "\n",
        "# Filter the subset for comments containing \"frustrat\" and \"cancer\"\n",
        "filtered_comments_subset_df = comments_subset_df.filter(\n",
        "    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n",
        ")\n",
        "\n",
        "# Preview the filtered DataFrame\n",
        "filtered_comments_subset_df.show(5)\n",
        "\n",
        "# Save the filtered subset to a test CSV file\n",
        "output_test_file = \"Test_Query_A2b.csv\"\n",
        "filtered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n",
        "\n",
        "print(f\"Test results saved to {output_test_file}\")\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "1c77c5be-01d5-4a73-be0b-1c872b18023f",
              "statement_id": 19,
              "statement_ids": [
                19
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": {
                "numbers": {
                  "SUCCEEDED": 4,
                  "UNKNOWN": 0,
                  "RUNNING": 0,
                  "FAILED": 0
                },
                "jobs": [
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 190,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 20,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\n# Previous Code to save as .csv \n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T03:18:02.297GMT",
                    "completionTime": "2024-11-25T03:18:03.279GMT",
                    "stageIds": [
                      27,
                      26
                    ],
                    "jobGroup": "19",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 45662716,
                    "dataRead": 396700700646,
                    "rowCount": 191434282,
                    "usageDescription": "",
                    "jobId": 19,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\n# Previous Code to save as .csv \n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:56:44.996GMT",
                    "completionTime": "2024-11-25T03:18:02.059GMT",
                    "stageIds": [
                      25
                    ],
                    "jobGroup": "19",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 0,
                    "dataRead": 0,
                    "rowCount": 0,
                    "usageDescription": "",
                    "jobId": 18,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\n# Previous Code to save as .csv \n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:56:44.305GMT",
                    "completionTime": "2024-11-25T02:56:44.726GMT",
                    "stageIds": [
                      24,
                      23
                    ],
                    "jobGroup": "19",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3678,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 1,
                    "numSkippedTasks": 3677,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 1,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 1,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  },
                  {
                    "displayName": "showString at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 45662716,
                    "dataRead": 396700700646,
                    "rowCount": 191434282,
                    "usageDescription": "",
                    "jobId": 17,
                    "name": "showString at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 19:\n# Previous Code to save as .csv \n\n# Filter the subset for comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_subset_df = comments_subset_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Preview the filtered DataFrame\nfiltered_comments_subset_df.show(5)\n\n# Save the filtered subset to a test CSV file\noutput_test_file = \"Test_Query_A2b.csv\"\nfiltered_comments_subset_df.write.csv(output_test_file, mode=\"overwrite\", header=True)\n\nprint(f\"Test results saved to {output_test_file}\")\n",
                    "submissionTime": "2024-11-25T02:35:38.552GMT",
                    "completionTime": "2024-11-25T02:56:44.182GMT",
                    "stageIds": [
                      22
                    ],
                    "jobGroup": "19",
                    "jobTags": [],
                    "status": "SUCCEEDED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 3677,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numCompletedIndices": 3677,
                    "numActiveStages": 0,
                    "numCompletedStages": 1,
                    "numSkippedStages": 0,
                    "numFailedStages": 0,
                    "killedTasksSummary": {}
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "1",
              "normalized_state": "finished",
              "queued_time": "2024-11-25T02:35:38.0871213Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-25T02:35:38.2902585Z",
              "execution_finish_time": "2024-11-25T03:18:05.471219Z",
              "parent_msg_id": "0ac4d1a0-e46b-408b-b44b-198dfee418e6"
            },
            "text/plain": "StatementMeta(1c77c5be-01d5-4a73-be0b-1c872b18023f, 1, 19, Finished, Available, Finished)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n|author|author_flair_css_class|author_flair_text|body|controversiality|created_utc|distinguished|edited|gilded| id|link_id|parent_id|retrieved_on|score|stickied|subreddit|subreddit_id|yyyy| mm|\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n+------+----------------------+-----------------+----+----------------+-----------+-------------+------+------+---+-------+---------+------------+-----+--------+---------+------------+----+---+\n\nTest results saved to Test_Query_A2b.csv\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732504685895
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Full Job \n",
        "# from pyspark.sql.functions import col, lower\n",
        "\n",
        "# # Filter comments containing \"frustrat\" and \"cancer\"\n",
        "# filtered_comments_df = comments_df.filter(\n",
        "#     (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n",
        "# )\n",
        "\n",
        "# # Save the filtered comments to a CSV file\n",
        "# output_file = \"Query_A2b.csv\"\n",
        "# filtered_comments_df.write.csv(output_file, mode=\"overwrite\", header=True)\n",
        "\n",
        "# # Preview the filtered DataFrame\n",
        "# filtered_comments_df.show(5)\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "ba5e360d-f184-47a0-9859-76b5031b79e3",
              "statement_id": 23,
              "statement_ids": [
                23
              ],
              "state": "finished",
              "livy_statement_state": "cancelled",
              "spark_jobs": {
                "numbers": {
                  "RUNNING": 0,
                  "UNKNOWN": 0,
                  "SUCCEEDED": 0,
                  "FAILED": 1
                },
                "jobs": [
                  {
                    "displayName": "csv at NativeMethodAccessorImpl.java:0",
                    "dataWritten": 659445,
                    "dataRead": 10502572209,
                    "rowCount": 92000413,
                    "usageDescription": "",
                    "jobId": 16,
                    "name": "csv at NativeMethodAccessorImpl.java:0",
                    "description": "Job group for statement 23:\nfrom pyspark.sql.functions import col, lower\n\n# Filter comments containing \"frustrat\" and \"cancer\"\nfiltered_comments_df = comments_df.filter(\n    (lower(col(\"body\")).contains(\"frustrat\")) & (lower(col(\"body\")).contains(\"cancer\"))\n)\n\n# Save the filtered comments to a CSV file\noutput_file = \"Query_A2b.csv\"\nfiltered_comments_df.write.csv(output_file, mode=\"overwrite\", header=True)\n\n# Preview the filtered DataFrame\nfiltered_comments_df.show(5)\n",
                    "submissionTime": "2024-11-24T21:46:37.938GMT",
                    "completionTime": "2024-11-24T21:48:20.247GMT",
                    "stageIds": [
                      21
                    ],
                    "jobGroup": "23",
                    "status": "FAILED",
                    "numTasks": 3677,
                    "numActiveTasks": 0,
                    "numCompletedTasks": 92,
                    "numSkippedTasks": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 8,
                    "numCompletedIndices": 92,
                    "numActiveStages": 0,
                    "numCompletedStages": 0,
                    "numSkippedStages": 0,
                    "numFailedStages": 1,
                    "killedTasksSummary": {
                      "Stage cancelled": 8
                    }
                  }
                ],
                "limit": 20,
                "rule": "ALL_DESC"
              },
              "session_id": "4",
              "normalized_state": "cancelled",
              "queued_time": "2024-11-24T21:46:36.8471617Z",
              "session_start_time": null,
              "execution_start_time": "2024-11-24T21:46:37.0619102Z",
              "execution_finish_time": "2024-11-24T21:48:21.8713127Z",
              "parent_msg_id": "5601befc-f3f0-4ae2-97e6-a98aa87c060b"
            },
            "text/plain": "StatementMeta(ba5e360d-f184-47a0-9859-76b5031b79e3, 4, 23, Finished, Cancelled, Cancelled)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1732484900127
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0",
      "mimetype": "text/x-python",
      "file_extension": ".py",
      "pygments_lexer": "ipython",
      "codemirror_mode": "ipython",
      "nbconvert_exporter": "python"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}